# -*- coding: utf-8 -*-
"""spam email detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MfS0kYNBfrbyV67rcIF7-_A5Mve8J6aH
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
import zipfile

# Load dataset from ZIP file
zip_path = "/content/spam_ham_dataset.csv (1).zip"  # Update with correct file path
with zipfile.ZipFile(zip_path, 'r') as z:
    file_name = z.namelist()[0]  # Get the first file inside ZIP
    with z.open(file_name) as f:
        df = pd.read_csv(f, encoding='latin-1')

#  Debug: Check column names
print("Columns in dataset:", df.columns)

#  Debug: Check first few rows
print("\nFirst 5 rows of dataset:\n", df.head())

# Ensure correct column selection
if 'label' not in df.columns or 'text' not in df.columns:
    print("\n ERROR: Expected columns 'label' and 'text' not found!")
    print("Available columns:", df.columns)
    exit()

# Convert 'label' to string in case it's not already
df['label'] = df['label'].astype(str)

#  Debug: Check unique values in 'label' column before encoding
print("Unique values in 'label' column before encoding:", df['label'].unique())

#  Fix: Standardize labels (remove spaces and convert to lowercase)
df['label'] = df['label'].str.strip().str.lower()

#  Fix: Encode labels correctly
label_mapping = {'spam': 1, 'ham': 0}
df = df[df['label'].isin(label_mapping)]  # Filter out invalid labels
df['label'] = df['label'].map(label_mapping)

#  Debug: Check unique values after encoding
print("Unique values in 'label' column after encoding:", df['label'].unique())

# Remove any missing values
df = df.dropna()

#  Debug: Check dataset size before splitting
print("Final dataset shape:", df.shape)

# Split data into training & test sets
if df.shape[0] < 2:  # Ensure enough data for split
    print("Error: Not enough data to split.")
    exit()

X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.3, random_state=42)

# Convert text to numerical features using TF-IDF Vectorizer
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Train NaÃ¯ve Bayes model
nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = nb.predict(X_test_tfidf)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}\n")
print("Classification Report:\n", classification_report(y_test, y_pred))

# Test with a new email
new_email = ["Congratulations! You've won a free iPhone. Click here to claim."]
new_email_tfidf = vectorizer.transform(new_email)
predicted_class = nb.predict(new_email_tfidf)

print("\nPredicted class:", "Spam" if predicted_class[0] == 1 else "Ham")

pip install gradio
import gradio as gr
import pandas as pd
import zipfile
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Function to load dataset
def load_dataset(uploaded_file):
    with zipfile.ZipFile(uploaded_file, 'r') as z:
        file_name = z.namelist()[0]  # Get the first file inside ZIP
        with z.open(file_name) as f:
            df = pd.read_csv(f, encoding='latin-1')
    return df

# Function to train the model
def train_model(df):
    df['label'] = df['label'].astype(str).str.strip().str.lower()
    label_mapping = {'spam': 1, 'ham': 0}
    df = df[df['label'].isin(label_mapping)]
    df['label'] = df['label'].map(label_mapping)
    df = df.dropna()

    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.3, random_state=42)
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)

    nb = MultinomialNB()
    nb.fit(X_train_tfidf, y_train)

    y_pred = nb.predict(X_test_tfidf)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    return vectorizer, nb, accuracy, report

# Function to classify an email
def classify_email(email, vectorizer, model):
    input_tfidf = vectorizer.transform([email])
    prediction = model.predict(input_tfidf)
    return "Spam" if prediction[0] == 1 else "Ham"

# Gradio Interface
def spam_detector(uploaded_file, email_text):
    df = load_dataset(uploaded_file)
    vectorizer, model, accuracy, report = train_model(df)
    prediction = classify_email(email_text, vectorizer, model)
    return f"Model Accuracy: {accuracy:.2f}\n\nClassification Report:\n{report}\n\nPrediction: {prediction}"

iface = gr.Interface(
    fn=spam_detector,
    inputs=[gr.File(label="Upload ZIP file"), gr.Textbox(label="Enter email to classify")],
    outputs=gr.Textbox(label="Result")
)

iface.launch()

pip install streamlit scikit-learn pandas

import streamlit as st
import pandas as pd
import zipfile
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Function to load dataset
def load_dataset(uploaded_file):
    with zipfile.ZipFile(uploaded_file, 'r') as z:
        file_name = z.namelist()[0]  # Get the first file inside ZIP
        with z.open(file_name) as f:
            df = pd.read_csv(f, encoding='latin-1')
    return df

# Function to train the model
def train_model(df):
    df['label'] = df['label'].astype(str).str.strip().str.lower()
    label_mapping = {'spam': 1, 'ham': 0}
    df = df[df['label'].isin(label_mapping)]
    df['label'] = df['label'].map(label_mapping)
    df = df.dropna()

    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.3, random_state=42)
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)

    nb = MultinomialNB()
    nb.fit(X_train_tfidf, y_train)

    y_pred = nb.predict(X_test_tfidf)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    return vectorizer, nb, accuracy, report

# Function to classify an email
def classify_email(email, vectorizer, model):
    input_tfidf = vectorizer.transform([email])
    prediction = model.predict(input_tfidf)
    return "Spam" if prediction[0] == 1 else "Ham"

# Streamlit UI
st.title("Spam Detector App")

uploaded_file = st.file_uploader("Upload a ZIP file containing the dataset", type="zip")

if uploaded_file:
    st.write("Processing dataset...")
    df = load_dataset(uploaded_file)
    vectorizer, model, accuracy, report = train_model(df)

    st.write(f"### Model Accuracy: {accuracy:.2f}")
    st.text(f"Classification Report:\n{report}")

    email_text = st.text_area("Enter email text for classification:")

    if st.button("Classify Email"):
        if email_text:
            prediction = classify_email(email_text, vectorizer, model)
            st.success(f"Prediction: {prediction}")
        else:
            st.warning("Please enter an email text for classification.")
